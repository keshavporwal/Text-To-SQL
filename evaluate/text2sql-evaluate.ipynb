{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12429776,"sourceType":"datasetVersion","datasetId":7840275}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-15T12:57:33.686409Z","iopub.execute_input":"2025-07-15T12:57:33.686574Z","iopub.status.idle":"2025-07-15T12:57:36.400959Z","shell.execute_reply.started":"2025-07-15T12:57:33.686558Z","shell.execute_reply":"2025-07-15T12:57:36.400171Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/minidev/mini_dev_postgresql.json\n/kaggle/input/minidev/dev_tables.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install transformers==4.51.3 accelerate sqlparse sql-metadata auto_gptq optimum --use-deprecated=legacy-resolver","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T12:57:36.401862Z","iopub.execute_input":"2025-07-15T12:57:36.402346Z","iopub.status.idle":"2025-07-15T12:59:24.497052Z","shell.execute_reply.started":"2025-07-15T12:57:36.402316Z","shell.execute_reply":"2025-07-15T12:59:24.496161Z"}},"outputs":[{"name":"stdout","text":"Collecting transformers==4.51.3\n  Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nRequirement already satisfied: sqlparse in /usr/local/lib/python3.11/dist-packages (0.5.3)\nCollecting sql-metadata\n  Downloading sql_metadata-2.17.0-py3-none-any.whl (22 kB)\nCollecting auto_gptq\n  Downloading auto_gptq-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting optimum\n  Downloading optimum-1.26.1-py3-none-any.whl (424 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.6/424.6 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from auto_gptq) (3.6.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from auto_gptq) (0.2.0)\nCollecting rouge (from auto_gptq)\n  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\nCollecting gekko (from auto_gptq)\n  Downloading gekko-1.3.0-py3-none-any.whl (13.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: peft>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from auto_gptq) (0.15.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2; platform_machine == \"x86_64\" or platform_machine == \"amd64\" or platform_machine == \"arm64\" or platform_machine == \"aarch64\" in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.51.3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.51.3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.51.3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.51.3) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.51.3) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.51.3) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (2025.6.15)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\" (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\" (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\" (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\" (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\" (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\" (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\" (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\" (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: triton==3.2.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1; python_version >= \"3.9\" in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->auto_gptq) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->auto_gptq) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->auto_gptq) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->auto_gptq) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->auto_gptq) (0.70.16)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from rouge->auto_gptq) (1.17.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.51.3) (2024.2.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.51.3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.51.3) (2022.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1; python_version >= \"3.9\"->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->auto_gptq) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->auto_gptq) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->auto_gptq) (2025.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.51.3) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.51.3) (1.4.0)\nInstalling collected packages: transformers, sql-metadata, rouge, gekko, auto_gptq, optimum, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed auto_gptq-0.7.1 gekko-1.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 optimum-1.26.1 rouge-1.0.1 sql-metadata-2.17.0 transformers-4.51.3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import json\n\ndef load_dataset(filename):\n    with open(filename, 'r') as f:\n        j = json.load(f)\n    return j\n\ndataset = load_dataset(\"/kaggle/input/minidev/mini_dev_postgresql.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T12:59:24.499221Z","iopub.execute_input":"2025-07-15T12:59:24.499481Z","iopub.status.idle":"2025-07-15T12:59:24.514649Z","shell.execute_reply.started":"2025-07-15T12:59:24.499458Z","shell.execute_reply":"2025-07-15T12:59:24.513972Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import json\n\ndef convert_json_to_schema(filename):\n    \"\"\"Convert a tables.json file into a python dictionary keeping the relevant schema information.\"\"\"\n    databases = {}\n    with open(filename, \"r\") as tables_json_file:\n        tables_json = json.load(tables_json_file)\n        for table_data in tables_json:\n            database_schema = []\n\n            table_names = table_data[\"table_names_original\"]\n            for table_name in table_names:\n                table_schema = {\n                    \"name\": table_name,\n                    \"columns\": [],\n                    \"primary_keys\": [],\n                    \"foreign_keys\": []\n                }\n                database_schema.append(table_schema)\n\n            column_names = table_data[\"column_names_original\"]\n            column_datatypes = table_data[\"column_types\"]\n            for [table_index, column_name], datatype in zip(column_names[1:], column_datatypes[1:]):\n                column_name = column_name.replace(\" \", \"_\")\n                column_name = column_name.replace(\"-\", \"_\")\n\n                if datatype == \"datetime\":\n                    datatype = \"timestamp\"\n                    \n                column = {\n                    \"name\": column_name,\n                    \"type\": datatype\n                }\n                database_schema[table_index][\"columns\"].append(column)\n\n            for primary_key in table_data[\"primary_keys\"]:\n                if type(primary_key) is int:\n                    primary_key = [primary_key,]\n\n                for key in primary_key:\n                    table_index = column_names[key][0]\n                    column_name = column_names[key][1]\n                    database_schema[table_index][\"primary_keys\"].append(column_name)\n\n            for foreign_key in table_data[\"foreign_keys\"]:\n                column_name = column_names[foreign_key[0]][1]\n                reference_table = database_schema[column_names[foreign_key[1]][0]][\"name\"]\n                reference_column = column_names[foreign_key[1]][1]\n                database_schema[column_names[foreign_key[0]][0]][\"foreign_keys\"].append({\n                    \"column\": column_name,\n                    \"references\": f\"{reference_table}({reference_column})\"\n                })\n\n            databases[table_data[\"db_id\"]] = database_schema\n\n    return databases\n\n\ndb = convert_json_to_schema(\"/kaggle/input/minidev/dev_tables.json\")\n\nprint(\"\\n\".join(list(db.keys())[:10]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T12:59:24.515463Z","iopub.execute_input":"2025-07-15T12:59:24.515710Z","iopub.status.idle":"2025-07-15T12:59:24.600408Z","shell.execute_reply.started":"2025-07-15T12:59:24.515687Z","shell.execute_reply":"2025-07-15T12:59:24.599712Z"}},"outputs":[{"name":"stdout","text":"debit_card_specializing\nfinancial\nformula_1\ncalifornia_schools\ncard_games\neuropean_football_2\nthrombosis_prediction\ntoxicology\nstudent_club\nsuperhero\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def get_normalized_create_statement(database_schema, filtered_tables=None):\n    \"\"\"Return database_schema as PostgreSQL normalized create table statements\"\"\"\n    schema_text = []\n    for table in database_schema:\n        if filtered_tables is None or table['name'] in filtered_tables:\n            create_table_text = f\"create table {table['name']} (\"\n            \n            # Columns\n            columns = []\n            for column in table[\"columns\"]:\n                column_def = f\"{column['name']} {column['type'].lower()}\"\n                columns.append(column_def)\n            create_table_text += (\"\\n\" + \",\\n\".join(columns))\n            \n            # Primary keys\n            if table[\"primary_keys\"]:\n                create_table_text += (f\",\\nprimary key ({', '.join(table['primary_keys'])})\")\n            \n            # Foreign keys\n            for fk in table[\"foreign_keys\"]:\n                create_table_text += (f\",\\nforeign key ({fk['column']}) references {fk['references']}\")\n\n            create_table_text += \"\\n);\"\n\n            schema_text.append(create_table_text)  \n    \n    return \"\\n\".join(schema_text)\n\nprint(get_normalized_create_statement(db[\"formula_1\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T12:59:24.601172Z","iopub.execute_input":"2025-07-15T12:59:24.601393Z","iopub.status.idle":"2025-07-15T12:59:24.607215Z","shell.execute_reply.started":"2025-07-15T12:59:24.601369Z","shell.execute_reply":"2025-07-15T12:59:24.606553Z"}},"outputs":[{"name":"stdout","text":"create table circuits (\ncircuitId integer,\ncircuitRef text,\nname text,\nlocation text,\ncountry text,\nlat real,\nlng real,\nalt integer,\nurl text,\nprimary key (circuitId)\n);\ncreate table constructors (\nconstructorId integer,\nconstructorRef text,\nname text,\nnationality text,\nurl text,\nprimary key (constructorId)\n);\ncreate table drivers (\ndriverId integer,\ndriverRef text,\nnumber integer,\ncode text,\nforename text,\nsurname text,\ndob date,\nnationality text,\nurl text,\nprimary key (driverId)\n);\ncreate table seasons (\nyear integer,\nurl text,\nprimary key (year)\n);\ncreate table races (\nraceId integer,\nyear integer,\nround integer,\ncircuitId integer,\nname text,\ndate date,\ntime text,\nurl text,\nprimary key (raceId),\nforeign key (circuitId) references circuits(circuitId),\nforeign key (year) references seasons(year)\n);\ncreate table constructorResults (\nconstructorResultsId integer,\nraceId integer,\nconstructorId integer,\npoints real,\nstatus text,\nprimary key (constructorResultsId),\nforeign key (constructorId) references constructors(constructorId),\nforeign key (raceId) references races(raceId)\n);\ncreate table constructorStandings (\nconstructorStandingsId integer,\nraceId integer,\nconstructorId integer,\npoints real,\nposition integer,\npositionText text,\nwins integer,\nprimary key (constructorStandingsId),\nforeign key (constructorId) references constructors(constructorId),\nforeign key (raceId) references races(raceId)\n);\ncreate table driverStandings (\ndriverStandingsId integer,\nraceId integer,\ndriverId integer,\npoints real,\nposition integer,\npositionText text,\nwins integer,\nprimary key (driverStandingsId),\nforeign key (driverId) references drivers(driverId),\nforeign key (raceId) references races(raceId)\n);\ncreate table lapTimes (\nraceId integer,\ndriverId integer,\nlap integer,\nposition integer,\ntime text,\nmilliseconds integer,\nprimary key (raceId, driverId, lap),\nforeign key (driverId) references drivers(driverId),\nforeign key (raceId) references races(raceId)\n);\ncreate table pitStops (\nraceId integer,\ndriverId integer,\nstop integer,\nlap integer,\ntime text,\nduration text,\nmilliseconds integer,\nprimary key (raceId, driverId, stop),\nforeign key (driverId) references drivers(driverId),\nforeign key (raceId) references races(raceId)\n);\ncreate table qualifying (\nqualifyId integer,\nraceId integer,\ndriverId integer,\nconstructorId integer,\nnumber integer,\nposition integer,\nq1 text,\nq2 text,\nq3 text,\nprimary key (qualifyId),\nforeign key (constructorId) references constructors(constructorId),\nforeign key (driverId) references drivers(driverId),\nforeign key (raceId) references races(raceId)\n);\ncreate table status (\nstatusId integer,\nstatus text,\nprimary key (statusId)\n);\ncreate table results (\nresultId integer,\nraceId integer,\ndriverId integer,\nconstructorId integer,\nnumber integer,\ngrid integer,\nposition integer,\npositionText text,\npositionOrder integer,\npoints real,\nlaps integer,\ntime text,\nmilliseconds integer,\nfastestLap integer,\nrank integer,\nfastestLapTime text,\nfastestLapSpeed text,\nstatusId integer,\nprimary key (resultId),\nforeign key (statusId) references status(statusId),\nforeign key (constructorId) references constructors(constructorId),\nforeign key (driverId) references drivers(driverId),\nforeign key (raceId) references races(raceId)\n);\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from sql_metadata import Parser\n\ndef create_prompt(d):\n    schema = get_normalized_create_statement(db[d[\"db_id\"]], Parser(d[\"SQL\"]).tables)\n    question = d[\"question\"] + (\" \" + d[\"evidence\"] if d[\"evidence\"] else \"\")\n    return f\"\"\"You are a data science expert. Below, you are provided with a database schema and a natural language question. Your task is to understand the schema and generate a valid PostgreSQL query to answer the question.\n    \nDatabase Schema:\n{schema}\n\nQuestion:\n{question}\n\nInstructions:\n- Make sure you only output the information that is asked in the question. If the question asks for a specific column, make sure to only include that column in the SELECT clause, nothing more.\n- The generated query should return all of the information asked in the question without any missing or extra information.\n- Before generating the final SQL query, please think through the steps of how to write the query. Do all the explanation before generating the final query.\n- Make sure to check the datatypes of the columns. For Example: if Date column has text datatype, do not use date functions on it, use string functions.\n- If you think some table information is missing or the database schema provided has no relevance with the question, do not answer with any SQL query.\n\nTake a deep breath and think step by step to find the correct SQL query.\n\"\"\"\n\nprint(create_prompt(dataset[0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T12:59:24.608023Z","iopub.execute_input":"2025-07-15T12:59:24.608222Z","iopub.status.idle":"2025-07-15T12:59:24.700818Z","shell.execute_reply.started":"2025-07-15T12:59:24.608198Z","shell.execute_reply":"2025-07-15T12:59:24.700263Z"}},"outputs":[{"name":"stdout","text":"You are a data science expert. Below, you are provided with a database schema and a natural language question. Your task is to understand the schema and generate a valid PostgreSQL query to answer the question.\n    \nDatabase Schema:\ncreate table customers (\nCustomerID integer,\nSegment text,\nCurrency text,\nprimary key (CustomerID)\n);\n\nQuestion:\nWhat is the ratio of customers who pay in EUR against customers who pay in CZK? ratio of customers who pay in EUR against customers who pay in CZK = count(Currency = 'EUR') / count(Currency = 'CZK').\n\nInstructions:\n- Make sure you only output the information that is asked in the question. If the question asks for a specific column, make sure to only include that column in the SELECT clause, nothing more.\n- The generated query should return all of the information asked in the question without any missing or extra information.\n- Before generating the final SQL query, please think through the steps of how to write the query. Do all the explanation before generating the final query.\n- Make sure to check the datatypes of the columns. For Example: if Date column has text datatype, do not use date functions on it, use string functions.\n- If you think some table information is missing or the database schema provided has no relevance with the question, do not answer with any SQL query.\n\nTake a deep breath and think step by step to find the correct SQL query.\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen2.5-Coder-7B-Instruct-GPTQ-Int4\"\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=\"auto\",\n    device_map=\"auto\"\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T12:59:24.701417Z","iopub.execute_input":"2025-07-15T12:59:24.701626Z","iopub.status.idle":"2025-07-15T13:00:36.991036Z","shell.execute_reply.started":"2025-07-15T12:59:24.701610Z","shell.execute_reply":"2025-07-15T13:00:36.990392Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31408f05beb146059d2b8edbbd36db74"}},"metadata":{}},{"name":"stderr","text":"2025-07-15 12:59:39.899529: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752584380.252629      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752584380.359821      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:410: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  @custom_fwd\n/usr/local/lib/python3.11/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:418: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  @custom_bwd\n/usr/local/lib/python3.11/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:461: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  @custom_fwd(cast_inputs=torch.float16)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ded89b48d8d4fccb6878063d2f2738b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e27c0b29dde84eb4a9255ca2293870d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e62f2f6f5254423b35462e505697d34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.58G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51ebb0dc60764402bf5f3f2238c9a3a4"}},"metadata":{}},{"name":"stderr","text":"Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"000ad07744f942a5a81b561d72419db0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d94afcd5cdaf4246b7801d947781d52e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6acd7168bd2a4cfc92b50a3b8b36770a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d96d31f4fc864204b8b2581964d40a0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c484050a5794700b81120500817e47b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9323dbd22e284c4f8e1fc3f529ae4a30"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(152064, 3584)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2DecoderLayer(\n        (self_attn): Qwen2Attention(\n          (k_proj): QuantLinear()\n          (o_proj): QuantLinear()\n          (q_proj): QuantLinear()\n          (v_proj): QuantLinear()\n        )\n        (mlp): Qwen2MLP(\n          (act_fn): SiLU()\n          (down_proj): QuantLinear()\n          (gate_proj): QuantLinear()\n          (up_proj): QuantLinear()\n        )\n        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"prompts_with_chat_template = []\nfor d in dataset:\n    prompt = create_prompt(d)\n    messages = [\n        {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n    \n    text = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n    prompts_with_chat_template.append(text)\n\nprint(prompts_with_chat_template[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T13:00:36.991800Z","iopub.execute_input":"2025-07-15T13:00:36.992462Z","iopub.status.idle":"2025-07-15T13:00:38.188185Z","shell.execute_reply.started":"2025-07-15T13:00:36.992440Z","shell.execute_reply":"2025-07-15T13:00:38.187585Z"}},"outputs":[{"name":"stdout","text":"<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nYou are a data science expert. Below, you are provided with a database schema and a natural language question. Your task is to understand the schema and generate a valid PostgreSQL query to answer the question.\n    \nDatabase Schema:\ncreate table customers (\nCustomerID integer,\nSegment text,\nCurrency text,\nprimary key (CustomerID)\n);\n\nQuestion:\nWhat is the ratio of customers who pay in EUR against customers who pay in CZK? ratio of customers who pay in EUR against customers who pay in CZK = count(Currency = 'EUR') / count(Currency = 'CZK').\n\nInstructions:\n- Make sure you only output the information that is asked in the question. If the question asks for a specific column, make sure to only include that column in the SELECT clause, nothing more.\n- The generated query should return all of the information asked in the question without any missing or extra information.\n- Before generating the final SQL query, please think through the steps of how to write the query. Do all the explanation before generating the final query.\n- Make sure to check the datatypes of the columns. For Example: if Date column has text datatype, do not use date functions on it, use string functions.\n- If you think some table information is missing or the database schema provided has no relevance with the question, do not answer with any SQL query.\n\nTake a deep breath and think step by step to find the correct SQL query.\n<|im_end|>\n<|im_start|>assistant\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def extract_query(response): # assuming the last code block with ```sql ``` has the final query\n    return response[response.rfind(\"```sql\\n\") + 7:response.rfind(\"```\")]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T13:00:38.189908Z","iopub.execute_input":"2025-07-15T13:00:38.190170Z","iopub.status.idle":"2025-07-15T13:00:39.137262Z","shell.execute_reply.started":"2025-07-15T13:00:38.190147Z","shell.execute_reply":"2025-07-15T13:00:39.136207Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ntry:\n    with open(\"output.json\", 'r+') as f:\n        responses = json.load(f)\nexcept FileNotFoundError:\n    responses = []\nfor text in tqdm(prompts_with_chat_template[len(responses):], desc=\"Generating\"):\n    model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n    generated_ids = model.generate(\n            **model_inputs,\n            max_new_tokens=1024\n        )\n    generated_ids = [\n        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n    ]\n\n    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\n    responses.append({\"response\": response, \"SQL\": extract_query(response)})\n    with open(\"output.json\", 'w+') as f:\n        json.dump(responses, f, indent=4)\n\nprint(len(responses))\nprint(responses[0]['SQL'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-15T13:00:39.138346Z","iopub.execute_input":"2025-07-15T13:00:39.138715Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating:   0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d52d04505ea494fa0ec4759d77f116e"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}